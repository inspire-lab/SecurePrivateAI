{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/inspire-lab/SecurePrivateAI/blob/main/3_defend_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiCBeUwVp9AS"
   },
   "source": [
    "# Defense with adversarial training\n",
    "\n",
    "In this section we will use adversarial training to harden our CNN against adversarial examples. \n",
    "\n",
    "In adversarial training the dataset get \"augmented\" with adversarial examples that are correctly labeled. This way the network learns that such perturbations are possible and can adapt to them.\n",
    "\n",
    "We will be using the IBM Adversarial Robustness Toolbox in this exercise. It offers a very easy-to-use implementation of adversarial training and a number of other defenses. \n",
    "https://github.com/IBM/adversarial-robustness-toolbox\n",
    "\n",
    "\n",
    "We start out by importing most of the modules and functions we will need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T20:27:50.161074Z",
     "start_time": "2021-09-20T20:27:48.453713Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install tensorflow-gpu==1.15.2 keras==2.2.3 adversarial-robustness-toolbox "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:30:14.009171Z",
     "start_time": "2021-09-20T21:30:12.996585Z"
    },
    "id": "SFCdbXWxp9AU"
   },
   "outputs": [],
   "source": [
    "# most of our imports\n",
    "import warnings\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from art.classifiers import KerasClassifier\n",
    "\n",
    "\n",
    "# helper code \n",
    "def extract_ones_and_zeroes( data, labels ):\n",
    "    data_zeroes = data[ np.argwhere( labels == 0 ).reshape( -1 ) ][ :200 ]\n",
    "    data_ones = data[ np.argwhere( labels == 1 ).reshape( -1 ) ][ :200 ]\n",
    "    x = np.vstack( (data_zeroes, data_ones) )\n",
    "\n",
    "    x = x / 255.\n",
    "    print( x.shape )\n",
    "\n",
    "    labels_zeroes = np.zeros( data_zeroes.shape[ 0 ] )\n",
    "    labels_ones = np.ones( data_ones.shape[ 0 ] )\n",
    "    y = np.append( labels_zeroes, labels_ones )\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def extract_two_classes( data, labels, classes=(0,1), no_instance=200 ):\n",
    "    data_zeroes = data[ np.argwhere( labels ==  classes[0] ).reshape( -1 ) ][ :no_instance ]\n",
    "    data_ones = data[ np.argwhere( labels == classes[1] ).reshape( -1 ) ][ :no_instance ]\n",
    "    x = np.vstack( (data_zeroes, data_ones) )\n",
    "    \n",
    "    # normalize the data\n",
    "    x = x / 255.\n",
    "\n",
    "    labels_zeroes = np.zeros( data_zeroes.shape[ 0 ] )\n",
    "    labels_ones = np.ones( data_ones.shape[ 0 ] )\n",
    "    y = np.append( labels_zeroes, labels_ones )\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def convert_to_keras_image_format( x_train, x_test ):\n",
    "    if keras.backend.image_data_format( ) == 'channels_first':\n",
    "        x_train = x_train.reshape( x_train.shape[ 0 ], 1, x_train.shape[ 1 ], x_train.shape[ 2 ] )\n",
    "        x_test = x_test.reshape( x_test.shape[ 0 ], 1, x_train.shape[ 1 ], x_train.shape[ 2 ] )\n",
    "    else:\n",
    "        x_train = x_train.reshape( x_train.shape[ 0 ], x_train.shape[ 1 ], x_train.shape[ 2 ], 1 )\n",
    "        x_test = x_test.reshape( x_test.shape[ 0 ], x_train.shape[ 1 ], x_train.shape[ 2 ], 1 )\n",
    "\n",
    "    return x_train, x_test\n",
    "\n",
    "\n",
    "def mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=2 ):\n",
    "    # define the classifier\n",
    "    clf = keras.Sequential( )\n",
    "    clf.add( Conv2D( 32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[ 1: ] ) )\n",
    "    clf.add( Conv2D( 64, (3, 3), activation='relu' ) )\n",
    "    clf.add( MaxPooling2D( pool_size=(2, 2) ) )\n",
    "    clf.add( Dropout( 0.25 ) )\n",
    "    clf.add( Flatten( ) )\n",
    "    clf.add( Dense( 128, activation='relu' ) )\n",
    "    clf.add( Dropout( 0.5 ) )\n",
    "    clf.add( Dense( y_train.shape[ 1 ], activation='softmax' ) )\n",
    "\n",
    "    clf.compile( loss=keras.losses.categorical_crossentropy,\n",
    "                 optimizer='adam',\n",
    "                 metrics=[ 'accuracy' ] )\n",
    "\n",
    "    clf.fit( x_train, y_train,\n",
    "             epochs=epochs,\n",
    "             verbose=1 )\n",
    "    clf.summary( )\n",
    "    score = clf.evaluate( x_test, y_test )\n",
    "    print( 'Test loss:', score[ 0 ] )\n",
    "    print( 'Test accuracy:', score[ 1 ] )\n",
    "\n",
    "    return clf\n",
    "\n",
    "\n",
    "def show_image( img ):\n",
    "    plt.imshow( img.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
    "    plt.axis( 'off' )\n",
    "    plt.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQb51r9Pp9AY"
   },
   "source": [
    "We start out by loading the data, preparing it and training our CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:30:17.234902Z",
     "start_time": "2021-09-20T21:30:14.010677Z"
    },
    "id": "Mi_KR9mVp9AZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# extract ones and zeroes\n",
    "x_train, y_train = extract_ones_and_zeroes( x_train, y_train )\n",
    "x_test, y_test = extract_ones_and_zeroes( x_test, y_test )\n",
    "\n",
    "# we need to bring the data in to a format that our cnn likes\n",
    "y_train = keras.utils.to_categorical( y_train, 2 )\n",
    "y_test = keras.utils.to_categorical( y_test, 2 )\n",
    "\n",
    "# convert it to a format keras can work with\n",
    "x_train, x_test = convert_to_keras_image_format(x_train, x_test)\n",
    "\n",
    "# need to some setup so everything gets executed in the same tensorflow session\n",
    "session = tf.Session( )\n",
    "keras.backend.set_session( session )\n",
    "\n",
    "# get and train our cnn\n",
    "clf = mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No-xgwJAp9Ae"
   },
   "source": [
    "We want to know how robust our model is against an attack. To do this we are calculating the `empirical robustness`. This is equivalent to computing the minimal perturbation that the attacker must introduce for a    successful attack. We are following the approach of Moosavi-Dezfooli et al. 2016 (paper link: https://arxiv.org/abs/1511.04599).\n",
    "\n",
    "The empirical robustness method supports two attacks at the moment.\n",
    "The `Fast Gradient Sign Method` and `Hop Skip and Jump`.\n",
    "\n",
    "You can use them by passing either `fgsm` or `hsj` as parameters.\n",
    "The default attack parameters are the following:\n",
    "```\n",
    "    \"fgsm\", {\"eps_step\": 0.1, \"eps_max\": 1., \"clip_min\": 0., \"clip_max\": 1.},\n",
    "    \"hsj\", {'max_iter': 50, 'max_eval': 10000, 'init_eval': 100, 'init_size': 100}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:30:17.864318Z",
     "start_time": "2021-09-20T21:30:17.237748Z"
    },
    "id": "SGO_xXwHp9Af"
   },
   "outputs": [],
   "source": [
    "from art.metrics import empirical_robustness\n",
    "\n",
    "# wrap the model an calculate empirical robustness\n",
    "wrapper = KerasClassifier( model=clf, clip_values=(0., 1.) )\n",
    "print( 'robustness of the undefended model', \n",
    "      empirical_robustness( wrapper, x_test, 'fgsm'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHoKCGrJWtIy"
   },
   "source": [
    "Try different attack parameters and compare the results. \n",
    "\n",
    "Tip:\n",
    "\n",
    "For `hsj` use only a few examples otherwise it will take forever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:44:56.570061Z",
     "start_time": "2021-09-20T21:44:56.468598Z"
    },
    "id": "GqNgpmoIWNTV"
   },
   "outputs": [],
   "source": [
    "### your code goes here\n",
    "x_small = x_test[ :10 ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfkJT6D_p9Ai"
   },
   "source": [
    "Let's create an adversarial example and see how it looks.\n",
    "We want to know how to the model performs on adversarial examples. Let's create adversarial examples out of the training set and see how the model does with it.\n",
    "\n",
    "Below you can the keyword arguments for the attack\n",
    "\n",
    "```\n",
    "norm=np.inf, eps=.3, eps_step=0.1, targeted=False, num_random_init=0, batch_size=1, minimal=False\n",
    "        \"\"\"\n",
    "        :param norm: The norm of the adversarial perturbation. Possible values: np.inf, 1 or 2.\n",
    "        :param eps: Attack step size (input variation)\n",
    "        :param eps_step: Step size of input variation for minimal perturbation computation\n",
    "        :param targeted: Indicates whether the attack is targeted (True) or untargeted (False)\n",
    "        :param num_random_init: Number of random initialisations within the epsilon ball. For random_init=0 starting at\n",
    "            the original input.\n",
    "        :param batch_size: Size of the batch on which adversarial samples are generated.\n",
    "        :param minimal: Indicates if computing the minimal perturbation (True). If True, also define `eps_step` for\n",
    "                        the step size and eps for the maximum perturbation.\n",
    "   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:30:19.583064Z",
     "start_time": "2021-09-20T21:30:19.282468Z"
    },
    "id": "-anGrCjjp9Aj"
   },
   "outputs": [],
   "source": [
    "# create an adversarial example with fgsm and plot it\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "fgsm = FastGradientMethod( wrapper, eps=0.4 )\n",
    "x_adv = fgsm.generate(x_test[128].reshape((1,28,28,1) ))\n",
    "print( 'class prediction for the adversarial sample:',\n",
    "       clf.predict( x_adv.reshape((1,28,28,1) ) ) )\n",
    "show_image( x_adv )\n",
    "\n",
    "# create adversarial examples for the all of the set\n",
    "# your code here\n",
    "x_test_adv = \n",
    "print( 'accuracy on adversarial examples:' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhEY7Iagp9Aw"
   },
   "source": [
    "## Adversarial Training\n",
    "\n",
    "Let's create a new untrained model with the same architecture that we have been using so far. \n",
    "\n",
    "We will train the model using adversarial training framework. The idea is very simple:\n",
    "\n",
    "1.   Train the model for 1 epoch\n",
    "2.   Create adversarial examples using FGSM \n",
    "3.   Enhance training data by mixing it with the adversarial examples. (Only mix in the adversarial examples created in this iteration)\n",
    "4.   Goto 1\n",
    "\n",
    "We will be using the FGSM attack from `art` this time.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:30:22.768988Z",
     "start_time": "2021-09-20T21:30:19.584820Z"
    },
    "id": "KfHrX6WftGOo"
   },
   "outputs": [],
   "source": [
    "# create a new untrained model and wrap it\n",
    "new_model = mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=0 )\n",
    "defended_model = KerasClassifier(clip_values=(0,1), model=new_model )\n",
    "# define the attack we are using\n",
    "fgsm = FastGradientMethod( defended_model, eps=.4 )\n",
    "\n",
    "# parameters\n",
    "epochs = 5 # number of iterations that we will perform training for\n",
    "ratio = .5  # ratio of the test set that will get turned into adversarial examples\n",
    "            # each iteration\n",
    "\n",
    "\n",
    "# some helpers\n",
    "idx = np.arange( x_train.shape[ 0 ], dtype=np.int )\n",
    "\n",
    "# create varialbes to hold the training data.\n",
    "# for now it is just the normal training data. we'll mix in the \n",
    "# adversarial examples in later\n",
    "x_train_enhanced = x_train\n",
    "y_train_enhanced = y_train\n",
    "\n",
    "\n",
    "for i in range( epochs ):\n",
    "  # train model for one epoch\n",
    "\n",
    "  # shuffle   \n",
    "\n",
    "  # pick the subset of the train data to turn into adversarial examples\n",
    "\n",
    "  # create adversarial examples\n",
    "\n",
    "  # add the adversarial examples to the training data\n",
    "\n",
    "\n",
    "# training is done. let's evaluate the performance on the test set\n",
    "# and adversarial examples\n",
    "acc = defended_model._model.evaluate( x_test, y_test )[ 1 ]\n",
    "print( 'acc on the test data: ', acc )\n",
    "\n",
    "# and now on adversarial examples\n",
    "x_test_adv = fgsm.generate( x_test )\n",
    "acc =  wrapper._model.evaluate( x_test_adv, y_test )\n",
    "print( 'accuracy on adversarial examples: ', acc )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhTCRfbCr6iq"
   },
   "source": [
    "To use the adversarial training that comes with `art` we need to pass our wrapped model to an `AdversarialTrainer` instance. The `AdversarialTrainer` also needs an instance of the attack that will be used to create the adversarial examples.\n",
    "\n",
    "https://adversarial-robustness-toolbox.readthedocs.io/en/latest/modules/defences/trainer.html#art.defences.trainer.AdversarialTrainer\n",
    "\n",
    "https://github.com/Trusted-AI/adversarial-robustness-toolbox/blob/main/examples/adversarial_training_cifar10.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:30:23.893487Z",
     "start_time": "2021-09-20T21:30:22.770668Z"
    },
    "id": "uxQZLbgBp9Ay",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from art.defences.trainer import AdversarialTrainer\n",
    "\n",
    "# get a new untrained model and warp it\n",
    "new_model = mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=0 )\n",
    "defended_model = KerasClassifier(clip_values=(0,1), model=new_model )\n",
    "# define the attack we are using\n",
    "fgsm = FastGradientMethod( defended_model, eps=0.4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3geBOs1p9A4"
   },
   "source": [
    "Create the `AdversarialTrainer` instance. \n",
    "Train the model and evaluate it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:30:25.844711Z",
     "start_time": "2021-09-20T21:30:23.896265Z"
    },
    "id": "8BWvgxNtp9A6"
   },
   "outputs": [],
   "source": [
    "# define the adversarial trainer and train the new network\n",
    "adversarial_trainer = AdversarialTrainer( defended_model, fgsm )\n",
    "adversarial_trainer.fit( x_train, y_train, batch_size=100, nb_epochs=5 )\n",
    "\n",
    "# evaluate how good our model is\n",
    "defended_model._model.evaluate( x_test,y_test )\n",
    "\n",
    "# and now on adversarial examples\n",
    "x_test_adv = fgsm.generate( x_test )\n",
    "acc =  wrapper._model.evaluate( x_test_adv, y_test )\n",
    "print( 'loss and accuracy on adversarial examples: ', acc )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KV0kBz2Fp9BA"
   },
   "source": [
    "Calculate the `empirical robustness` for our now hopefully more robust model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:30:26.233877Z",
     "start_time": "2021-09-20T21:30:25.846524Z"
    },
    "id": "Q7CROH1Gp9BE"
   },
   "outputs": [],
   "source": [
    "# calculate the empiracal robustness\n",
    "print( 'robustness of the defended model', \n",
    "      empirical_robustness( defended_model, x_test[0:], 'fgsm', {}) )\n",
    "\n",
    "x_adv = fgsm.generate(x_test[0].reshape((1,28,28,1) ))\n",
    "print( 'class prediction for the adversarial sample:',\n",
    "       clf.predict( x_adv.reshape((1,28,28,1) ) ) \n",
    "     )\n",
    "plt.imshow( x_adv.reshape( 28, 28 ), cmap=\"gray_r\" )\n",
    "plt.axis( 'off' )\n",
    "plt.show( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPL9ywQnKu2w"
   },
   "source": [
    "# Defensive Distillation\n",
    "\n",
    "The idea behind defensive distillation is to transfer robustness from one network to another. To do this we are training two networks. The first network, which we will call `one` is trained normally. We want to transfer some of *experience* to our second network, called `two`. Both `one` and `two` have the same architecture. The way we achieve is this is by training `two` with the outputs of `one`. An important change is that we are using a so called *temperature* `T` parameter in the softmax function.\n",
    "The process is as follows:\n",
    "\n",
    "\n",
    "1.   Train `one` at temperature `T`\n",
    "2.   Create new labels for the training data using `one`\n",
    "3.   Train `two` at temperature `T` using the new labels\n",
    "\n",
    "\n",
    "Hints:\n",
    "\n",
    "\n",
    "*   `tf.math.exp`\n",
    "*   `keras.backend.in_train_phase`\n",
    "*   kullback leibler divergence\n",
    "\n",
    "Loss: $H(\\sigma (z^T/ρ), \\sigma (z^S/ρ))$ , T: teacher, S: student, H: Entropy Loss\n",
    "\n",
    "Fig: ![kd](https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11263-021-01453-z/MediaObjects/11263_2021_1453_Fig4_HTML.png)\n",
    "\n",
    "Ref:\n",
    "\n",
    "* https://arxiv.org/pdf/1503.02531.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:30:31.234121Z",
     "start_time": "2021-09-20T21:30:26.235453Z"
    },
    "id": "DHdXvFx1Sud0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# softmax with temperature\n",
    "T = 10\n",
    "def softmax_with_temp( x ):\n",
    "  return keras.backend.in_train_phase(\n",
    "      # your code here\n",
    "      ??? # using temperature,\n",
    "      tf.nn.softmax( x )\n",
    "  )\n",
    "  \n",
    "\n",
    "# define the classifier one\n",
    "one = keras.Sequential( )\n",
    "one.add( Conv2D( 32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[ 1: ] ) )\n",
    "one.add( Flatten( ) )\n",
    "one.add( Dense( 128, activation='relu' ) )\n",
    "one.add( Dense( y_train.shape[ 1 ], activation=softmax_with_temp ) )\n",
    "\n",
    "\n",
    "# train the classifier one and evaluate on clean test data.\n",
    "# your code here\n",
    "???\n",
    "\n",
    "one.summary( )\n",
    "\n",
    "score = one.evaluate( x_test, y_test )\n",
    "print( 'Test loss:', score[ 0 ] )\n",
    "print( 'Test accuracy:', score[ 1 ] )\n",
    "\n",
    "\n",
    "# test the FGSM attack\n",
    "one_wrapped = KerasClassifier(clip_values=(0,1), model=one )\n",
    "fgsm = FastGradientMethod( one_wrapped, eps=0.4 )\n",
    "x_test_adv = fgsm.generate( x_test )\n",
    "acc =  one.evaluate( x_test_adv, y_test )\n",
    "print( 'accuracy on adversarial examples: ', acc )\n",
    "\n",
    "# create new labels\n",
    "y_train_new = one.predict( x_train )\n",
    "\n",
    "\n",
    "# define the classifier two\n",
    "two = keras.Sequential( )\n",
    "two.add( Conv2D( 32, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[ 1: ] ) )\n",
    "two.add( Flatten( ) )\n",
    "two.add( Dense( 128, activation='relu' ) )\n",
    "two.add( Dense( y_train.shape[ 1 ], activation=softmax_with_temp ) )\n",
    "\n",
    "# train the classifier two and evaluate on clean test data\n",
    "# your code here\n",
    "???\n",
    "\n",
    "\n",
    "two.summary( )\n",
    "score = two.evaluate( x_test, y_test )\n",
    "print( 'Test loss:', score[ 0 ] )\n",
    "print( 'Test accuracy:', score[ 1 ] )\n",
    "\n",
    "\n",
    "# test the FGSM attack\n",
    "\n",
    "print( 'accuracy on adversarial examples: ', acc )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3d2J443nA9k8"
   },
   "source": [
    "# Black box attacks\n",
    "\n",
    "Assume we do not have access to the internal workings of our target model. This means we can not easily calculate gradients.\n",
    "Fortunately or unfortunate depending on how you are looking at it adversarial examples created on one model can be also used against a different model. Given their learned decision boundary is similar enough.\n",
    "\n",
    "We do not know what the target model looks like but in most cases we know the domain that it works in, MNIST in our case, so we can make an educated guess. We then train our model with the architecture that we guessed and create adversarial examples using this model. If our model and the target model are similar enough the adversarial examples can be transfered.\n",
    "\n",
    "\n",
    "In the code below we will be training two different models and see if the adversarial examples transfer from one to the other.\n",
    "\n",
    "Fig: ![bba](https://miro.medium.com/max/1400/1*6FUwsVaUsrtzmKUO_YP-8A.png)\n",
    "\n",
    "Ref: https://arxiv.org/abs/1602.02697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-20T21:30:38.878664Z",
     "start_time": "2021-09-20T21:30:31.235840Z"
    },
    "id": "ay5X8686uwA3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as k\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Reshape\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# extract ones and zeroes\n",
    "x_train, y_train = extract_ones_and_zeroes( x_train, y_train )\n",
    "x_test, y_test = extract_ones_and_zeroes( x_test, y_test )\n",
    "\n",
    "# we need to bring the data in to a format that our cnn likes\n",
    "y_train = keras.utils.to_categorical( y_train, 2 )\n",
    "y_test = keras.utils.to_categorical( y_test, 2 )\n",
    "\n",
    "# convert it to a format keras can work with\n",
    "x_train, x_test = convert_to_keras_image_format(x_train, x_test)\n",
    "\n",
    "# Create simple CNN\n",
    "model_0 = mnist_cnn_model( x_train, y_train, x_test, y_test, epochs=5 )\n",
    "print( model_0.evaluate( x_test, y_test )[ 1 ] )\n",
    "\n",
    "\n",
    "# create a simple DNN\n",
    "model_1 = Sequential()\n",
    "model_1.add( Reshape(  [28 * 28 ], input_shape=x_train.shape[ 1: ] ) )# flatten the data\n",
    "model_1.add( Dense( 512, activation='relu' ) ) \n",
    "model_1.add( Dense( 128, activation='relu' ) ) \n",
    "model_1.add( Dense( 2, activation='softmax' ) ) \n",
    "\n",
    "# train model_1\n",
    "# your code here\n",
    "???\n",
    "\n",
    "# compare how the models do on the test set\n",
    "# your code here\n",
    "???\n",
    "print( 'acc model 0: ', acc_0 )\n",
    "print( 'acc model 1: ', acc_1 )\n",
    "\n",
    "\n",
    "# compare how the models perform on adversarial examples\n",
    "# your code here\n",
    "???\n",
    "print( 'acc model 0 on adversarial examples: ',  ??? )\n",
    "print( 'acc model 1 on adversarial examples: ',  ??? )\n",
    "\n",
    "\n",
    "# let's see how the models do when we give them the adversarial examples \n",
    "# created against the other model\n",
    "print( 'acc model 0 on adversarial examples from model 1: ', ??? )\n",
    "print( 'acc model 1 on adversarial examples from model 0: ', ??? )\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "defend_cnn_solution.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/podschwadt/aml_tutorial/blob/master/defend_cnn.ipynb",
     "timestamp": 1543716203670
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}