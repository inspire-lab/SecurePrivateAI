{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "fl and sl.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/inspire-lab/SecurePrivateAI/blob/master/8_fl_and_sl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3G_Tg5ONqOK",
    "colab_type": "text"
   },
   "source": [
    "# Privacy Preserving Machine Learning\n",
    "\n",
    "First things first. Let's run the package installations. They take quite a while.\n",
    "\n",
    "Add the end of the installation you need to hit the restart button. "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# installation\n",
    "\n",
    "Due to the version conflict, you may stop this session and goes to\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/inspire-lab/SecurePrivateAI/blob/master/9_sl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "Otherwise, you need to restart the runtime after the installation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# first install it\n",
    "# and it's conflict with tensorflow-federeated==0.19.0\n",
    "# You need to restart the runtime\n",
    "\n",
    "!pip install syft==0.2.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split Learning and Pysyft\n",
    "\n",
    "Split learning considers from another perspective\n",
    "\n",
    "![pipeline](https://github.com/inspire-lab/SecurePrivateAI/raw/main/images/SL.png)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# you need to import the PyTorch library first\n",
    "# otherwise, it's easy to raise an error.\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import syft as sy\n",
    "\n",
    "# allow pysyft to work its magic on torch tensors\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "# create a virtual worker. in an actual setting this would be on a different machine\n",
    "client = sy.VirtualWorker( hook, id='client' )\n",
    "\n",
    "# define a tensor and send it to the client\n",
    "x = torch.tensor([1,2,3,4,5])\n",
    "# this leaves us with a pointer to the tensor\n",
    "x_pointer = x.send( client )\n",
    "\n",
    "# check out some meta data\n",
    "print( x_pointer )\n",
    "print( client._objects )\n",
    "\n",
    "# we can use this pointers like normal tensors\n",
    "result = x_pointer + x_pointer\n",
    "print( result )\n",
    "\n",
    "# if we want the result we can call get() to send the tensor back to us\n",
    "result_local = result.get()\n",
    "# once we call get() it removes the tensor from the other side and our pointer\n",
    "# becomes invalid\n",
    "print( result_local )\n",
    "print( client._objects )\n",
    "# print( result )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import syft as sy\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "# Data preprocessing\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "train_set = datasets.MNIST('mnist', download=True, train=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define our model segments\n",
    "\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 640]\n",
    "output_size = 10\n",
    "\n",
    "models = [\n",
    "    nn.Sequential(\n",
    "                nn.Linear(input_size, hidden_sizes[0]),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                nn.ReLU(),\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "                nn.Linear(hidden_sizes[1], output_size),\n",
    "                nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create optimisers for each segment and link to their segment\n",
    "optimizers = [\n",
    "    optim.SGD(model.parameters(), lr=0.03,)\n",
    "    for model in models\n",
    "]\n",
    "\n",
    "# create some workers\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "workers = alice, bob\n",
    "\n",
    "# Send Model Segments to starting locations\n",
    "model_locations = [alice, bob]\n",
    "\n",
    "for model, location in zip(models, model_locations):\n",
    "    model.send(location)\n",
    "\n",
    "def train(x, target, models, optimizers):\n",
    "    # Training Logic\n",
    "\n",
    "    #1) erase previous gradients (if they exist)\n",
    "    for opt in optimizers:\n",
    "        opt.zero_grad()\n",
    "\n",
    "    #2) make a prediction\n",
    "    a = models[0](x)\n",
    "\n",
    "    #3) break the computation graph link, and send the activation signal to the next model\n",
    "    remote_a = a.move(models[1].location, requires_grad=True)\n",
    "\n",
    "    #4) make prediction on next model using received signal\n",
    "    pred = models[1](remote_a)\n",
    "\n",
    "    #5) calculate how much we missed\n",
    "    criterion = nn.NLLLoss()\n",
    "    loss = criterion(pred, target)\n",
    "\n",
    "    #6) figure out which weights caused us to miss\n",
    "    loss.backward()\n",
    "\n",
    "    # 7) send gradient of the received activation signal to the model behind\n",
    "    # grad_a = remote_a.grad.copy().move(models[0].location)\n",
    "\n",
    "    # 8) backpropagate on bottom model given this gradient\n",
    "    # a.backward(grad_a)\n",
    "\n",
    "    #9) change the weights\n",
    "    for opt in optimizers:\n",
    "        opt.step()\n",
    "\n",
    "    #10) print our progress\n",
    "    return loss.detach().get()\n",
    "\n",
    "for i in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.send(alice)\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        labels = labels.send(bob)\n",
    "\n",
    "        loss = train(images, labels, models, optimizers)\n",
    "        running_loss += loss\n",
    "\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(i, running_loss/len(train_loader)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "def test(x, target, models, optimizers):\n",
    "    # Training Logic\n",
    "\n",
    "    #1) erase previous gradients (if they exist)\n",
    "    for opt in optimizers:\n",
    "        opt.zero_grad()\n",
    "\n",
    "    #2) make a prediction with 4 parties\n",
    "    a = models[0](x)\n",
    "    remote_a = a.move(models[1].location, requires_grad=True)\n",
    "\n",
    "    pred = models[1](remote_a)\n",
    "\n",
    "    # 3) print our progress\n",
    "    return pred.detach().get()\n",
    "\n",
    "num_correct = 0\n",
    "total = 0\n",
    "test_set = datasets.MNIST('mnist', download=True, train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.send(alice)\n",
    "    images = images.view(images.shape[0], -1)\n",
    "    predictions = test(images, labels, models, optimizers)\n",
    "    print(predictions.shape)\n",
    "    print(labels.shape)\n",
    "    num_correct += (predictions.max(dim=1)[1] == labels).sum()\n",
    "    total += labels.size(0)\n",
    "    print(f\"Test Accuracy of the model: {float(num_correct)/float(total)*100:.2f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "More references:\n",
    "\n",
    "https://learnopencv.com/federated-learning-using-pytorch-and-pysyft/\n",
    "\n",
    "https://github.com/OpenMined/PySyft/tree/syft_0.2.x/examples/tutorials/advanced/split_neural_network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}