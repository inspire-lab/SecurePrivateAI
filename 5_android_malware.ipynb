{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "android_malware.ipynb",
   "provenance": [],
   "private_outputs": true,
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/inspire-lab/SecurePrivateAI/blob/master/5_android_malware.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Hy_8YxiXNr1",
    "colab_type": "text"
   },
   "source": [
    "We are using [androguard](https://github.com/androguard/androguard) to perform apk analysis. We are using a small data set that is available on [kaggle](https://www.kaggle.com/xwolf12/datasetandroidpermissions). \n",
    "\n",
    "We will also use some live android malware as well as a (hopefully ;) ) clean android app. The cell below downloads the data we need through this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "99-9GWOoT-aH",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!pip install androguard\n",
    "!pip install tensorflow-gpu==1.15.2  keras==2.2.3 cleverhans==2.1.0\n",
    "!wget https://github.com/duckduckgo/Android/releases/download/5.36.3/duckduckgo-5.36.3-release.apk\n",
    "!wget 'https://docs.google.com/uc?export=download&id=1_eK_o1Jdp0K8lIVptcgfrn3x546bbc3d' -O android_permissions.csv\n",
    "!wget https://github.com/ashishb/android-malware/raw/master/fake_bankers/eba335956afad3b50a93effc61cd7467552ff0f7c8ac14032f784c5fec3a5720.apk -O fake_banker.apk\n",
    "!wget https://raw.githubusercontent.com/ashishb/android-malware/master/feabme/com.tinker.jumperchess\\(Jump%20Chess\\).apk -O feabme.apk\n",
    "!wget https://github.com/ashishb/android-malware/raw/master/TrojanDownloader.Agent.JI/Google-play.apk -O TrojanDownloader.apk\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaZPx8AdYUhV",
    "colab_type": "text"
   },
   "source": [
    "Below is some help code that is mostly about data handling. It provides function to split the data in tow the two different classes as well as perform the test and train split."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4O7GNX3Rp5_z",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def split_by_class(  x, y, MALWARE_LABEL=1, BEGING_LABEL=0 ):\n",
    "  \"\"\"\n",
    "  Return two datasets. one for benign and one for malicious\n",
    "  :param x:\n",
    "  :param y:\n",
    "  :return: (x_mal, y_mal), (x_beg, y_beg)\n",
    "  \"\"\"\n",
    "\n",
    "  # saftey checks\n",
    "  size = x.shape[ 0 ]\n",
    "  assert (size == y.shape[ 0 ])\n",
    "\n",
    "  # converted to category labels\n",
    "  if hasattr( y[ 0 ], 'shape' ) and  len( y[0].shape) != 0 and y[ 0 ].shape[ 0 ] > 1:\n",
    "    mal_label = to_categorical( MALWARE_LABEL, 2 )\n",
    "    beg_label = to_categorical( BEGING_LABEL, 2 )\n",
    "    # cause numpy is fun\n",
    "    i_m = (y == mal_label).all( axis=1 ).nonzero( )[ 0 ]\n",
    "    i_x = (y == beg_label).all( axis=1 ).nonzero( )[ 0 ]\n",
    "  else:\n",
    "    i_m = np.argwhere( y == MALWARE_LABEL )[ :, 0 ]\n",
    "    i_x = np.argwhere( y == BEGING_LABEL )[ :, 0 ]\n",
    "\n",
    "  x_mal = x[ i_m ][ : ]\n",
    "  y_mal = y[ i_m ][ : ]\n",
    "\n",
    "  x_beg = x[ i_x ][ : ]\n",
    "  y_beg = y[ i_x ][ : ]\n",
    "\n",
    "  print( 'Malware: ', x_mal.shape )\n",
    "  print( 'Goodware: ', x_beg.shape )\n",
    "\n",
    "  # saftey checks\n",
    "  assert (size == x_mal.shape[ 0 ] + x_beg.shape[ 0 ])\n",
    "  assert (size == y_mal.shape[ 0 ] + y_beg.shape[ 0 ])\n",
    "\n",
    "  return (x_mal, y_mal), (x_beg, y_beg)\n",
    "\n",
    "\n",
    "def training_and_test( x, y, split=0.75, balance_classes=False,\n",
    "                      MALWARE_LABEL=1, BEGING_LABEL=0, **kwargs ):\n",
    "  \"\"\"\n",
    "  Splits the data set into training set. If x or y is None the data is loaded \n",
    "  or processed.\n",
    "  :param x:\n",
    "  :param y:\n",
    "  :param split: percentage of the training going into the training data\n",
    "  :balance_classes: keep the ratio of classes in training and test set\n",
    "  :return: (x_train, y_train), (x_test, y_test)\n",
    "  \"\"\"\n",
    "  # safety checks\n",
    "  size = x.shape[ 0 ]\n",
    "  assert (size == y.shape[ 0 ])\n",
    "\n",
    "  print( 'X: ', x.shape )\n",
    "  print( 'Y: ', y.shape )\n",
    "\n",
    "  rand = np.random.RandomState( )\n",
    "  rand.seed( 7 )\n",
    "  if balance_classes:\n",
    "    (x_mal, y_mal), (x_beg, y_beg) = split_by_class( x, y )\n",
    "    p_mal = rand.permutation( x_mal.shape[ 0 ] )\n",
    "    p_beg = rand.permutation( x_beg.shape[ 0 ] )\n",
    "    # training set\n",
    "    print( y_beg[ p_beg ][ : int( x.shape[ 0 ] * split ) ].shape )\n",
    "    x_train = np.vstack( (x_mal[ p_mal ][ : int( x_mal.shape[ 0 ] * split ) ],\n",
    "                        x_beg[ p_beg ][ : int( x_beg.shape[ 0 ] * split ) ]) )\n",
    "    if len( y.shape ) ==1 :\n",
    "      y_train = np.concatenate( (y_mal[ p_mal ][ : int( x_mal.shape[ 0 ] * split ) ],\n",
    "                            y_beg[ p_beg ][ : int( x_beg.shape[ 0 ] * split ) ]),\n",
    "                            axis=None )\n",
    "    else:\n",
    "      y_train = np.vstack( (y_mal[ p_mal ][ : int( x_mal.shape[ 0 ] * split ) ],\n",
    "                            y_beg[ p_beg ][ : int( x_beg.shape[ 0 ] * split ) ]) )\n",
    "    # test set\n",
    "    x_test = np.vstack( (x_mal[ p_mal ][ int( x_mal.shape[ 0 ] * split ): ],\n",
    "                        x_beg[ p_beg ][ int( x_beg.shape[ 0 ] * split ): ]) )\n",
    "    if len( y.shape ) ==1 :\n",
    "      y_test = np.concatenate( (y_mal[ p_mal ][ int( x_mal.shape[ 0 ] * split ): ],\n",
    "                          y_beg[ p_beg ][ int( x_beg.shape[ 0 ] * split ): ]),\n",
    "                            axis=None )\n",
    "    else:\n",
    "      y_test = np.vstack( (y_mal[ p_mal ][ int( x_mal.shape[ 0 ] * split ): ],\n",
    "                          y_beg[ p_beg ][ int( x_beg.shape[ 0 ] * split ): ]) )\n",
    "  else:\n",
    "    p = rand.permutation( x.shape[ 0 ] )\n",
    "    x_train = x[ p ][ : int( x.shape[ 0 ] * split ) ]\n",
    "    y_train = y[ p ][ : int( x.shape[ 0 ] * split ) ]\n",
    "    x_test = x[ p ][ int( x.shape[ 0 ] * split ): ]\n",
    "    y_test = y[ p ][ int( x.shape[ 0 ] * split ): ]\n",
    "\n",
    "  print( 'X_train: ', x_train.shape, type( x_train ) )\n",
    "  print( 'Y_train: ', y_train.shape, type( y_train ) )\n",
    "  print( 'X_test: ', x_test.shape, type( x_test ) )\n",
    "  print( 'Y_test: ', y_test.shape, type( y_test ) )\n",
    "  # safety checks\n",
    "  assert (size == x_train.shape[ 0 ] + x_test.shape[ 0 ])\n",
    "  assert (size == y_train.shape[ 0 ] + y_test.shape[ 0 ])\n",
    "\n",
    "  return (x_train, y_train), (x_test, y_test)\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KB9buyUp5c_",
    "colab_type": "text"
   },
   "source": [
    "Next we'll read in the csv file and parse it. the first line gives us the names of the permissions. After that each line represents an instance. A 1 indicates that a certain feature/permission is present while a 0 indicates that it is not. The last value of the line gives us the class. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qAlg61I8LlEN",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "with open( 'android_permissions.csv', 'r' ) as f:\n",
    "  lines = f.readlines()\n",
    "\n",
    "permissions = lines[ 0 ].split( ';' )[ :-1 ]\n",
    "print( 'all knonw permissions' )\n",
    "print( permissions )\n",
    "\n",
    "x = [ ]\n",
    "y = [ ]\n",
    "for line in lines[ 1: ]:\n",
    "    features = line.rstrip( '\\n' ).split( ';' )\n",
    "    arr = [ int( i ) for i in features[ : -1 ] ]\n",
    "    x.append( arr )\n",
    "    y.append(  int( features[ -1 ] ) )\n",
    "f.close( )\n",
    "x = np.array( x )\n",
    "y = np.array( y )\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = training_and_test( x, y, \n",
    "                                                         balance_classes=True)\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUz5JAXrdW2W",
    "colab_type": "text"
   },
   "source": [
    "Before we dive into learning from the data. Let's take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xgfCQS8-CFkv",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print( x_train.shape )\n",
    "print( y_train.shape )\n",
    "\n",
    "(x_mal, y_mal), (x_beg, y_beg) = split_by_class( x_train, y_train )\n",
    "\n",
    "print( 'MALWARE' )\n",
    "mal = x_mal.sum( axis=0 )\n",
    "plt.bar( np.arange( mal.shape[ 0 ] ), mal )\n",
    "plt.show()\n",
    "argsorted = np.flip( np.argsort( mal ) )\n",
    "for i in range(10):\n",
    "  print( permissions[ argsorted[ i ] ] + ': ' + str( mal[ argsorted[ i ] ] )  )\n",
    "\n",
    "print( 'BENIGN' )\n",
    "beg = x_beg.sum( axis=0 )\n",
    "plt.bar( np.arange( beg.shape[ 0 ] ), beg )\n",
    "plt.show()\n",
    "argsorted = np.flip( np.argsort( beg ) )\n",
    "for i in range(10):\n",
    "  print( permissions[ argsorted[ i ] ] + ': ' + str( beg[ argsorted[ i ] ] )  )\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9cPxxzveT-I",
    "colab_type": "text"
   },
   "source": [
    "Using what you have learned so far, create an svm classifier, train it on that training data and evaluate it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E0BomuoDfp45",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# your code here"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tgoy9oAghQ66",
    "colab_type": "text"
   },
   "source": [
    "In this task accuracy is not the most important meassure. A more important way of meassuring the effectivness of our classifier is false negative and false positve rate. The function below allows us to compute it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8rlB-vAZ6pFe",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def metrics( y_true, y_pred ):\n",
    "  # convert from categorial labels if required\n",
    "  if len( y_pred[ 0 ].shape ) != 0:\n",
    "    y_pred = np.argmax( y_pred, axis=1 )\n",
    "  if len( y_true[ 0 ].shape ) != 0:\n",
    "    y_true = np.argmax( y_true, axis=1 )\n",
    "  tn, fp, fn, tp = confusion_matrix( y_true, y_pred, labels=[ 0, 1 ] ).ravel( )\n",
    "  return { 'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp }\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "h4Ue37j86y_Y",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print( clf.predict( x_test ) )\n",
    "print( metrics( y_test, clf.predict( x_test ) ) )\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8wkbc0plWax",
    "colab_type": "text"
   },
   "source": [
    "Let's see how our classifier work to new apks. We just downloaded a few at the beginning of the notebook. First we need to extract the permissions from the apk. \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "61CDZJKYfbC0",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from androguard.misc import AnalyzeAPK\n",
    "import re\n",
    "\n",
    "def extract_permissions( apk, dv_formant, analysis ):\n",
    "  print( apk.get_app_name() )\n",
    "  print( 'permissions' )\n",
    "  apk_permissions = apk.get_permissions()\n",
    "  print( apk_permissions )\n",
    "\n",
    "  # create empty feature vector\n",
    "  apk_features = np.zeros( [ len( permissions ) ] )\n",
    "\n",
    "  for perm in apk_permissions:\n",
    "    if not isinstance( perm, str ):\n",
    "      continue\n",
    "    try:\n",
    "      idx = permissions.index( perm )\n",
    "    except:\n",
    "      print( 'encountered unknown permission:' + perm )  \n",
    "    apk_features[ idx ] = 1\n",
    "\n",
    "  return apk_features\n",
    "\n",
    "def predict_svm( x ):\n",
    "  print( clf.predict( x ) )\n",
    "  "
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dl1vRasPmSlc",
    "colab_type": "text"
   },
   "source": [
    "If we wanted to get more elaborate with our feature extraction. The code below extracts suspicous API calls and URL that are used in the app.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wNURQL9I8ngB",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def suspicous_api_and_urls ( apk, dv_formant, analysis ):\n",
    "  \"\"\"\n",
    "  taken from\n",
    "  https://github.com/MLDroid/drebin\n",
    "  \"\"\"\n",
    "\n",
    "  print( apk.get_app_name() )\n",
    "  SuspiciousApiSet = set()\n",
    "  URLDomainSet = set()\n",
    "  for dv in dv_formant:\n",
    "    for m in dv.get_methods():\n",
    "      for block in analysis.get_method( m ).get_basic_blocks().get():\n",
    "        DalvikCodeList = []\n",
    "        for Instruction in block.get_instructions():\n",
    "            CodeLine = str(Instruction.get_name() + \" \" + Instruction.get_output())\n",
    "            DalvikCodeList.append(CodeLine)\n",
    "        DalvikCodeList = set(DalvikCodeList)\n",
    "        ApiList = []\n",
    "        AndroidSuspiciousApiNameList = [\"getExternalStorageDirectory\", \"getSimCountryIso\", \"execHttpRequest\", \n",
    "                    \"sendTextMessage\", \"getSubscriberId\", \"getDeviceId\", \"getPackageInfo\", \"getSystemService\", \"getWifiState\", \n",
    "                    \"setWifiEnabled\", \"setWifiDisabled\", \"Cipher\"]\n",
    "        OtherSuspiciousApiNameList = [\"Ljava/net/HttpURLconnection;->setRequestMethod(Ljava/lang/String;)\", \"Ljava/net/HttpURLconnection\", \n",
    "                                      \"Lorg/apache/http/client/methods/HttpPost\", \"Landroid/telephony/SmsMessage;->getMessageBody\", \n",
    "                                      \"Ljava/io/IOException;->printStackTrace\", \"Ljava/lang/Runtime;->exec\"]\n",
    "        NotLikeApiNameList = [\"system/bin/su\", \"android/os/Exec\"]\n",
    "        for DalvikCode in DalvikCodeList:\n",
    "          if \"invoke-\" in DalvikCode:\n",
    "              Parts = DalvikCode.split(\",\")\n",
    "              for Part in Parts:\n",
    "                  if \";->\" in Part:\n",
    "                      Part = Part.strip()\n",
    "                      if Part.startswith('Landroid'):\n",
    "                          FullApi = Part\n",
    "                          ApiParts = FullApi.split(\";->\")\n",
    "                          ApiClass = ApiParts[0].strip()\n",
    "                          ApiName = ApiParts[1].split(\"(\")[0].strip()\n",
    "                          ApiDetails = {}\n",
    "                          ApiDetails['FullApi'] = FullApi\n",
    "                          ApiDetails['ApiClass'] = ApiClass\n",
    "                          ApiDetails['ApiName'] = ApiName\n",
    "                          ApiList.append(ApiDetails)\n",
    "                          if(ApiName in AndroidSuspiciousApiNameList):\n",
    "                              #ApiClass = Api['ApiClass'].replace(\"/\", \".\").replace(\"Landroid\", \"android\").strip()\n",
    "                              SuspiciousApiSet.add(ApiClass+\".\"+ApiName)\n",
    "                  for Element in OtherSuspiciousApiNameList:\n",
    "                      if(Element in Part):\n",
    "                          SuspiciousApiSet.add(Element)\n",
    "          for Element in NotLikeApiNameList:\n",
    "              if Element in DalvikCode:\n",
    "                  SuspiciousApiSet.add(Element)\n",
    "        for Instruction in DalvikCodeList:\n",
    "          URLSearch = re.search(\"https?://([\\da-z\\.-]+\\.[a-z\\.]{2, 6}|[\\d.]+)[^'\\\"]*\", Instruction, re.IGNORECASE)\n",
    "          if (URLSearch):\n",
    "              URL = URLSearch.group()\n",
    "              Domain = re.sub(\"https?://(.*)\", \"\\g<1>\",\n",
    "                              re.search(\"https?://([^/:\\\\\\\\]*)\", URL, re.IGNORECASE).group(), 0, re.IGNORECASE)\n",
    "              URLDomainSet.add(Domain)\n",
    "\n",
    "  print( SuspiciousApiSet )\n",
    "  print( URLDomainSet )\n",
    "  return SuspiciousApiSet, URLDomainSet\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYRv15l6CSov",
    "colab_type": "text"
   },
   "source": [
    "Now that we have a trained classifier and a way to extract features from APK files we can see how are classifier perform on apps that were not part of the dataset.\n",
    "\n",
    "Complete the code sub below to classify the apps."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VUlxHhTQdOKT",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# list of apk filenames\n",
    "apks =  [ 'duckduckgo-5.36.3-release.apk', 'fake_banker.apk', 'feabme.apk',\n",
    "         'TrojanDownloader.apk' ]\n",
    "# labels\n",
    "labels = [ 0, 1, 1, 1 ]\n",
    "\n",
    "# analyze the apks\n",
    "\n",
    "# extract features\n",
    "\n",
    "# perform inference\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6s_WnrBe_B_",
    "colab_type": "text"
   },
   "source": [
    "How does the classifier perform? Check against www.virustotal.com \n",
    "(You need to download and upload the files)\n",
    "\n",
    "\n",
    "Download links:\n",
    "https://github.com/duckduckgo/Android/releases/download/5.36.3/duckduckgo-5.36.3-release.apk\n",
    "\n",
    "https://github.com/ashishb/android-malware/raw/master/fake_bankers/eba335956afad3b50a93effc61cd7467552ff0f7c8ac14032f784c5fec3a5720.apk \n",
    "https://raw.githubusercontent.com/ashishb/android-malware/master/feabme/com.tinker.jumperchess\\(Jump%20Chess\\).apk \n",
    "https://github.com/ashishb/android-malware/raw/master/TrojanDownloader.Agent.JI/Google-play.apk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuS-F096yHq8",
    "colab_type": "text"
   },
   "source": [
    "Of course we are not limited to SVMs for malware detection. We can use neural nets too. The code below builds a and trains a simple neural network. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6rjR9w1xhHvh",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "# from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train_cat = to_categorical( y_train )  \n",
    "y_test_cat = to_categorical( y_test )  \n",
    "\n",
    "model = Sequential()\n",
    "model.add( Dense( 64, activation='relu', input_shape=x_train.shape[ 1: ]  ) )\n",
    "model.add( Dense( 32, activation='relu' ) )\n",
    "model.add( Dense( 2, activation='softmax' ) )\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "model.fit( x_train, y_train_cat, epochs=64 )\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sS7MmGTE2BXP",
    "colab_type": "text"
   },
   "source": [
    "How does the neural network perform when compared against our SVM classifier we trained earlier? \n",
    "Compare the relevant metrics on the test set and the 4 APKs we downloaded."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "U-afwgFK_314",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# evaluate model performance\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmw3bdmw2g8Z",
    "colab_type": "text"
   },
   "source": [
    "Of course the neural model is vulnerable to same attacks we discussed earlier. But in the malware setting we are not free to make any change we want.\n",
    "We need to constrain ourselves, so we can \"easily\" make the modifications to the APK without changing its functionality. A common constraint is to only add features.\n",
    "\n",
    "Another constraint is that we can only make a change of exactly 1 since our features are binary. There is no 0.1 change. It is only on or off.\n",
    "We deal with this by rounding up our down in the code below.\n",
    "\n",
    "For the moment lets ignore the first constraint.\n",
    "\n",
    "Let's build a simple FGSM attack with rounding and attack the model we trained above.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RDFSRXBqAVUQ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import tensorflow as tf\n",
    "from cleverhans.utils_tf import model_loss\n",
    "import keras\n",
    "\n",
    "epsillon = .1 # rate of change\n",
    "alpha = 0.5 # threshold for rounding\n",
    "\n",
    "# we don't want training phase beahviour\n",
    "keras.layers.core.K.set_learning_phase( 0 )\n",
    "\n",
    "# Set TF random seed to improve reproducibility\n",
    "tf.set_random_seed( 1234 )\n",
    "\n",
    "# we need the tensorflow session to run the attack\n",
    "sess = keras.backend.get_session()\n",
    "\n",
    "# compute natural loss\n",
    "\n",
    "\n",
    "# forward pass\n",
    "\n",
    "\n",
    "# compute gradient\n",
    "\n",
    "\n",
    "# find next sample\n",
    "\n",
    "\n",
    "# make sure we are in the correct range\n",
    "\n",
    "\n",
    "# rounding\n",
    "\n",
    "\n",
    "# compute adversarial loss\n",
    "loss_adv = model_loss( y_test_cat, model( x_tensor ), mean=False )\n",
    "\n",
    "# run the attack\n",
    "x_adv = sess.run( x_tensor )\n",
    "\n",
    "\n",
    "print( 'chagens that were made' )\n",
    "print( np.sum( x_adv, axis=1 ) - np.sum( x_test, axis=1 ) )\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pb7Fm0XyHuud",
    "colab_type": "text"
   },
   "source": [
    "How does the attack perform? Evaluate the created examples."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "svY3vl_nH1re",
    "colab_type": "code",
    "colab": {}
   },
   "source": [],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUgpfT7XH2AM",
    "colab_type": "text"
   },
   "source": [
    "A more powerful version of the attack is an iterative version. Modify the code above to make the attack iterative. Additionally, the attack currently still regards our first constraint. How would that be changed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkszhap7JPCk",
    "colab_type": "text"
   },
   "source": [
    "It is time to analyze the adversarial examples that we have created. Using code from earlier check which features where added the most often. Also do the samples work against the SVM classifier?\n",
    "\n",
    "Bonus question for homework: with the androguard tool you can repakage apks. Make the changes to the manifest suggested by the adversarial examples, repakage the apk and see how it fares against virustotal.\n"
   ]
  }
 ]
}