{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "keras.ipynb",
   "provenance": [],
   "authorship_tag": "ABX9TyNkhZUNAKXUAC/1JXKkxIc1",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/inspire-lab/SecurePrivateAI/blob/master/1_intro/intro_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3S2J-EHf3TTZ",
    "colab_type": "text"
   },
   "source": [
    "Taken from the www.keras.io quickstart guide and their github page: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py and https://github.com/podschwadt/teaching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrL70Vax3xgu",
    "colab_type": "text"
   },
   "source": [
    "# Getting started: 30 seconds to Keras\n",
    "The core data structure of Keras is a model, a way to organize layers. The simplest type of model is the Sequential model, a linear stack of layers. For more complex architectures, you should use the Keras functional API, which allows to build arbitrary graphs of layers.\n",
    "\n",
    "Here is the `Sequential` model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "h_ol-vVt3Swx",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from keras.models import Sequential\n",
    "import keras\n",
    "\n",
    "model = Sequential()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0y6B-T-3_yf",
    "colab_type": "text"
   },
   "source": [
    "Stacking layers is as easy as `.add()`:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f7sNe1dI3_k7",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model.add(Dense(units=64, activation='relu', input_dim=784))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-zO5U4x4NFN",
    "colab_type": "text"
   },
   "source": [
    "Once your model looks good, configure its learning process with `.compile()`:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3RQHCSS44SDG",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqEGSwoi4UxP",
    "colab_type": "text"
   },
   "source": [
    "If you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6I1e-v2Y4Wro",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tASphwuh5Uua",
    "colab_type": "text"
   },
   "source": [
    "Now that we have model we need some data to feed it. Let's load the MNIST hadnwritten digites and bring them into the correct form for our model ot use."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b7DdWOCt5nTJ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from keras.datasets import mnist\n",
    "# the data, split between train and test sets\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qq7VIVcY55iE",
    "colab_type": "text"
   },
   "source": [
    "The image is loaded as integers. We need it to be floats between 0 and 1 though. On top of that our model only takes one dimensional arrays as input.\n",
    "\n",
    "Squash the values to be in the interval `[0,1]` and reshape the individual to be one dimensional arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SHV-G8G6nc1",
    "colab_type": "text"
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ARzJpxp46pfq",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "x_train = x_train.reshape( x_train.shape[ 0 ], -1 )\n",
    "x_test = x_test.reshape( x_test.shape[ 0 ], -1 )\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60tSESOt4Y-4",
    "colab_type": "text"
   },
   "source": [
    "### Training:\n",
    "\n",
    "You can now iterate on your training data in batches. But first we need to transform "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ChwtyAho4e_4",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)\n",
    "\n",
    "# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32)\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ma4fyp_-4jUb",
    "colab_type": "text"
   },
   "source": [
    "Evaluate your performance in one line:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "db9L8FXa4wvO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "model.evaluate(x_test, y_test, batch_size=128)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IR16CQn540xZ",
    "colab_type": "text"
   },
   "source": [
    "Or generate predictions on new data:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VYUtuFaF41sq",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "model.predict(x_test, batch_size=128)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOaQ163f_zZo",
    "colab_type": "text"
   },
   "source": [
    "## More than 30 seconds\n",
    "\n",
    "Let's create a CNN doing classification on MNIST\n",
    "\n",
    "(taken from: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVNniQ7uBasG",
    "colab_type": "text"
   },
   "source": [
    "Let's start by importing the functions and classes we want to use."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pLh8SZFqA9_q",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "'''\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1FEqR2ADkks",
    "colab_type": "text"
   },
   "source": [
    "Next we are setting some the hyperparameters batch size and epochs.\n",
    "\n",
    "And some convience information about the data such as image dimensions and the nubmer of classes.\n",
    "\n",
    "Finally we load the data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6SNERgVuDjpO",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# some hyperparameters \n",
    "batch_size = 128\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print( x_train.shape )"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJ7NazkUEEmm",
    "colab_type": "text"
   },
   "source": [
    "Before we can feed the data to our network we need to perform some transformations.\n",
    "\n",
    "\n",
    "\n",
    "1.   2 dimensional convolutions expect the image to have multiple color channels our images currently have no channels so we simlpy add a single channel. This is done depending on where keras expects the channel information to be. `channels_first` means the the channel information will be the second axis of our numpy array. `channels_last` means the channel is the last axis. \n",
    "2.   Change the dataype to float\n",
    "3.   Quantize the data to be in $[0,1]$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JUVF58JiCjgT",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8MuFMxqFZeD",
    "colab_type": "text"
   },
   "source": [
    "To perform multiclass classification we need to tranform the labels as well. Currently they are integers $\\in [0,9]$\n",
    "\n",
    "But we need them in one-hot encoded. To transform a number `x` into a one-hot encoded or categorical class label we set the value of an arrray to `1` at index `x`. All other values are `0`. The length of the array is the number of classes.\n",
    "\n",
    "For example:\n",
    "`3 -> [ 0, 0, 0, 1, 0, 0, 0, 0, 0, 0 ]`\n",
    "\n",
    "Thankfully keras does that for us."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "otG8v_sxCyFi",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLm-DtLTG4XB",
    "colab_type": "text"
   },
   "source": [
    "Next we define our CNN. Note that only the first layer needs and input shape. The shape information for the other layers can be infered from the previous layers."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y0Wi-PPgC3TC",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZkkB8fBHO0b",
    "colab_type": "text"
   },
   "source": [
    "Keras models need to be compiled ( right now. this probably changed with tensorflow 2). This makes the model ready for execution. We need to pass a loss function, an optimizer and any metrics that we would like to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HHUc0GR2C5pj",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAc9oXpEHl19",
    "colab_type": "text"
   },
   "source": [
    "Now we can train the model. We only need to pass the instance and the labels all other parameters are optional and have reasonalbe default values for most cases. The fit methode will also chop up our data into batches so we can just pass it al.\n",
    "\n",
    "\n",
    "##!!!! NOTE:\n",
    "In this case the test data is passed as validation data. If you want to make any claims about your model's performance on unseen test data this is a big no no and is only here for demonstraion."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "h4RBEfV0C7MD",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymbG5E3xIVlt",
    "colab_type": "text"
   },
   "source": [
    "Finally we can see how our model does on the test data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yoGOR_9UC_lE",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}